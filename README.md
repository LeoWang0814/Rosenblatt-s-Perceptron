# Rosenblatt's Perceptron å¯è§†åŒ– / Visualization of Rosenblatt's Perceptron

æœ¬é¡¹ç›®å±•ç¤ºäº† Rosenblatt æ„ŸçŸ¥æœºï¼ˆPerceptronï¼‰ç®—æ³•åœ¨é€»è¾‘é—¨å­¦ä¹ ä¸­çš„è®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶ä»¥è¡¨æ ¼å½¢å¼æ‰“å°å‡ºæ¯æ¬¡è¿­ä»£ä¸­æƒé‡çš„å˜åŒ–ã€é¢„æµ‹è¾“å‡ºå’Œæƒé‡æ›´æ–°å€¼ï¼Œå¸®åŠ©ç†è§£å…¶å­¦ä¹ æœºåˆ¶ã€‚

This project visualizes the training process of the Rosenblatt Perceptron algorithm with an example of learning a logic gate (e.g., AND gate). The output shows each epochâ€™s weight updates, predictions, and learning deltas in a clear tabular format, helping users understand how the perceptron learns.

---

## ğŸ“Œ ç‰¹æ€§ Features

- ä½¿ç”¨ Python å®ç°æ„ŸçŸ¥æœºæ ¸å¿ƒè®­ç»ƒç®—æ³•  Use Python to implement the perceptron core training algorithm.
- æ”¯æŒè‡ªå®šä¹‰è®­ç»ƒæ•°æ®ï¼ˆé»˜è®¤ä¸º AND é—¨æ•°æ®ï¼‰  Support custom training data (default is AND gate data).
- æ¯ä¸€æ­¥è®­ç»ƒè¿‡ç¨‹çš„è¯¦ç»†å¯è§†åŒ–è¾“å‡º  Detailed visual output of each step of the training process.
- æ— éœ€å¤–éƒ¨ä¾èµ–ï¼Œç›´æ¥è¿è¡Œ  No external dependencies are required.

---

## ğŸ§  æ„ŸçŸ¥æœºç®€ä»‹ What is a Perceptron?

æ„ŸçŸ¥æœºæ˜¯ä¸€ç§äºŒåˆ†ç±»çº¿æ€§åˆ†ç±»å™¨ï¼Œæ˜¯äººå·¥ç¥ç»ç½‘ç»œçš„åŸºç¡€æ„ä»¶ã€‚å®ƒé€šè¿‡è°ƒæ•´æƒé‡æ¥å­¦ä¹ è¾“å…¥ä¸ç›®æ ‡è¾“å‡ºä¹‹é—´çš„å…³ç³»ã€‚

The perceptron is a simple binary linear classifier and a fundamental building block in neural networks. It learns to distinguish between two classes by adjusting its weights based on input-output errors.

---

## ğŸ“‚ é¡¹ç›®ç»“æ„ Project Structure

```

Rosenblatt-s-Perceptron/
â”œâ”€â”€ main.py         # ä¸»ç¨‹åº Main script for training visualization
â”œâ”€â”€ README.md             # é¡¹ç›®è¯´æ˜æ–‡æ¡£ This file

````

---

## â–¶ï¸ ä½¿ç”¨æ–¹æ³• How to Run

ç¡®ä¿ä½ å·²ç»å®‰è£…äº† Pythonï¼ˆæ— éœ€é¢å¤–ä¾èµ–ï¼‰ã€‚

è¾“å‡ºå†…å®¹å°†å±•ç¤ºæ¯ä¸€è½® (epoch) ä¸­æ¯ä¸€ä¸ªæ ·æœ¬çš„è®­ç»ƒè¿‡ç¨‹ï¼ŒåŒ…æ‹¬ï¼š

* å½“å‰æƒé‡ (Initial Weights)
* è¾“å…¥å€¼ (Inputs)
* ç›®æ ‡è¾“å‡º (Target)
* å®é™…è¾“å‡º (Output)
* æ›´æ–°å€¼ (Deltas)
* æ›´æ–°åçš„æƒé‡ (Updated Weights)

---

## ğŸ§ª ç¤ºä¾‹æ•°æ® Example Data (AND Gate)

```python
testData = [[1, -1, -1, -1],
            [1, 1, -1, -1],
            [1, -1, 1, -1],
            [1, 1, 1, 1]]  # AND gate
```

* è¾“å…¥å‰ä¸‰ä¸ªå€¼ä¸ºåç½®é¡¹ `x0=1` ä¸ä¸¤ä¸ªç‰¹å¾ `x1`, `x2`
* ç¬¬å››ä¸ªå€¼ä¸ºç›®æ ‡è¾“å‡º `target`
* æ„ŸçŸ¥æœºé€šè¿‡å¤šä¸ª epoch è¿­ä»£è®­ç»ƒï¼Œä½¿å¾—è¾“å‡ºé€æ¸æ¥è¿‘ç›®æ ‡

---

## ğŸ“Š è¾“å‡ºç¤ºä¾‹ Output Sample

```
 Epoch |   i   |  w0      w1      w2   |  x0      x1      x2   |target  output   delta |deltaW0 deltaW1 deltaW2|finalW0 finalW1 finalW2
   1   |   1   |   0       0       0   |   1      -1      -1   |  -1       1      -2   | -0.2     0.2     0.2  | -0.2     0.2     0.2  
   ...
```

---

## ğŸ“– å­¦ä¹ ç”¨é€” Learning Purpose

è¿™ä¸ªç¨‹åºé€‚ç”¨äºï¼š

* åˆå­¦ç¥ç»ç½‘ç»œçš„å­¦ç”Ÿ
* æœºå™¨å­¦ä¹ è¯¾å ‚æ•™å­¦å¯è§†åŒ–æ¼”ç¤º
* ç†è§£æ„ŸçŸ¥æœºç®—æ³•æƒé‡æ›´æ–°æœºåˆ¶çš„ç”¨æˆ·

This program is ideal for:

* Students new to neural networks
* In-class visualization demos for ML courses
* Anyone wanting to understand how perceptrons update weights during training

---

## ğŸ“„ è®¸å¯è¯ License

MIT License

---

æ¬¢è¿ star â­ æˆ– fork ğŸ´ï¼
Feel free to â­ star or ğŸ´ fork the project!
